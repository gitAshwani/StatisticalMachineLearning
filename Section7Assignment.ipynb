{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb847fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ParamHelpers\n",
      "\n",
      "Warning message: 'mlr' is in 'maintenance-only' mode since July 2019.\n",
      "Future development will only happen in 'mlr3'\n",
      "(<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be\n",
      "uncaught bugs meanwhile in {mlr} - please consider switching.\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    train\n",
      "\n",
      "\n",
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "Loading required package: rpart\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "Loading required package: doParallel\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: 'e1071'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    impute\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'plotly'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    last_plot\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following object is masked from 'package:graphics':\n",
      "\n",
      "    layout\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'MASS'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:plotly':\n",
      "\n",
      "    select\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set environment params\n",
    "Sys.setenv(LANG='en')  # English\n",
    "\n",
    "# Import libraries\n",
    "library(mlr)           # ML toolkit\n",
    "library(caret)         # ML toolkit\n",
    "library(nnet)          # class.ind() function\n",
    "library(neuralnet)     # Deep Neural Networks\n",
    "library(LiblineaR)     # LR Lasso (l1)\n",
    "library(randomForest)  # Random Forest\n",
    "library(adabag)        # Boosting\n",
    "library(e1071)         # SVM\n",
    "library(ggplot2)       # Visualization\n",
    "library(plotly)        # 3D visualization\n",
    "library(leaps)\n",
    "\n",
    "# Import data\n",
    "library(ISLR)      # Data from the course book\n",
    "library(MASS)      # Boston housing dataset\n",
    "library(datasets)  # US crime dataset\n",
    "\n",
    "# Resize plot\n",
    "library(repr)  # String and binary representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e82eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>6819</li><li>96</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 6819\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 6819\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 6819   96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 96</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Bankrupt.</th><th scope=col>ROA.C..before.interest.and.depreciation.before.interest</th><th scope=col>ROA.A..before.interest.and...after.tax</th><th scope=col>ROA.B..before.interest.and.depreciation.after.tax</th><th scope=col>Operating.Gross.Margin</th><th scope=col>Realized.Sales.Gross.Margin</th><th scope=col>Operating.Profit.Rate</th><th scope=col>Pre.tax.net.Interest.Rate</th><th scope=col>After.tax.net.Interest.Rate</th><th scope=col>Non.industry.income.and.expenditure.revenue</th><th scope=col>⋯</th><th scope=col>Net.Income.to.Total.Assets</th><th scope=col>Total.assets.to.GNP.price</th><th scope=col>No.credit.Interval</th><th scope=col>Gross.Profit.to.Sales</th><th scope=col>Net.Income.to.Stockholder.s.Equity</th><th scope=col>Liability.to.Equity</th><th scope=col>Degree.of.Financial.Leverage..DFL.</th><th scope=col>Interest.Coverage.Ratio..Interest.expense.to.EBIT.</th><th scope=col>Net.Income.Flag</th><th scope=col>Equity.to.Liability</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>0.3705943</td><td>0.4243894</td><td>0.4057498</td><td>0.6014572</td><td>0.6014572</td><td>0.9989692</td><td>0.7968871</td><td>0.8088094</td><td>0.3026464</td><td>⋯</td><td>0.7168453</td><td>0.009219440</td><td>0.6228790</td><td>0.6014533</td><td>0.8278902</td><td>0.2902019</td><td>0.02660063</td><td>0.5640501</td><td>1</td><td>0.01646874</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>0.4642909</td><td>0.5382141</td><td>0.5167300</td><td>0.6102351</td><td>0.6102351</td><td>0.9989460</td><td>0.7973802</td><td>0.8093007</td><td>0.3035564</td><td>⋯</td><td>0.7952971</td><td>0.008323302</td><td>0.6236517</td><td>0.6102365</td><td>0.8399693</td><td>0.2838460</td><td>0.26457682</td><td>0.5701749</td><td>1</td><td>0.02079431</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>0.4260713</td><td>0.4990188</td><td>0.4722951</td><td>0.6014500</td><td>0.6013635</td><td>0.9988574</td><td>0.7964034</td><td>0.8083875</td><td>0.3020352</td><td>⋯</td><td>0.7746697</td><td>0.040002853</td><td>0.6238410</td><td>0.6014493</td><td>0.8367743</td><td>0.2901885</td><td>0.02655472</td><td>0.5637061</td><td>1</td><td>0.01647411</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>0.3998440</td><td>0.4512647</td><td>0.4577333</td><td>0.5835411</td><td>0.5835411</td><td>0.9986997</td><td>0.7969670</td><td>0.8089656</td><td>0.3033495</td><td>⋯</td><td>0.7395545</td><td>0.003252475</td><td>0.6229287</td><td>0.5835376</td><td>0.8346971</td><td>0.2817212</td><td>0.02669663</td><td>0.5646634</td><td>1</td><td>0.02398233</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1</td><td>0.4650222</td><td>0.5384322</td><td>0.5222978</td><td>0.5987835</td><td>0.5987835</td><td>0.9989731</td><td>0.7973661</td><td>0.8093037</td><td>0.3034750</td><td>⋯</td><td>0.7950159</td><td>0.003877563</td><td>0.6235207</td><td>0.5987815</td><td>0.8399727</td><td>0.2785138</td><td>0.02475185</td><td>0.5756166</td><td>1</td><td>0.03549020</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1</td><td>0.3886803</td><td>0.4151766</td><td>0.4191338</td><td>0.5901714</td><td>0.5902507</td><td>0.9987581</td><td>0.7969032</td><td>0.8087706</td><td>0.3031158</td><td>⋯</td><td>0.7104205</td><td>0.005277875</td><td>0.6226046</td><td>0.5901723</td><td>0.8299390</td><td>0.2850871</td><td>0.02667537</td><td>0.5645383</td><td>1</td><td>0.01953448</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 96\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & Bankrupt. & ROA.C..before.interest.and.depreciation.before.interest & ROA.A..before.interest.and...after.tax & ROA.B..before.interest.and.depreciation.after.tax & Operating.Gross.Margin & Realized.Sales.Gross.Margin & Operating.Profit.Rate & Pre.tax.net.Interest.Rate & After.tax.net.Interest.Rate & Non.industry.income.and.expenditure.revenue & ⋯ & Net.Income.to.Total.Assets & Total.assets.to.GNP.price & No.credit.Interval & Gross.Profit.to.Sales & Net.Income.to.Stockholder.s.Equity & Liability.to.Equity & Degree.of.Financial.Leverage..DFL. & Interest.Coverage.Ratio..Interest.expense.to.EBIT. & Net.Income.Flag & Equity.to.Liability\\\\\n",
       "  & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 0.3705943 & 0.4243894 & 0.4057498 & 0.6014572 & 0.6014572 & 0.9989692 & 0.7968871 & 0.8088094 & 0.3026464 & ⋯ & 0.7168453 & 0.009219440 & 0.6228790 & 0.6014533 & 0.8278902 & 0.2902019 & 0.02660063 & 0.5640501 & 1 & 0.01646874\\\\\n",
       "\t2 & 1 & 0.4642909 & 0.5382141 & 0.5167300 & 0.6102351 & 0.6102351 & 0.9989460 & 0.7973802 & 0.8093007 & 0.3035564 & ⋯ & 0.7952971 & 0.008323302 & 0.6236517 & 0.6102365 & 0.8399693 & 0.2838460 & 0.26457682 & 0.5701749 & 1 & 0.02079431\\\\\n",
       "\t3 & 1 & 0.4260713 & 0.4990188 & 0.4722951 & 0.6014500 & 0.6013635 & 0.9988574 & 0.7964034 & 0.8083875 & 0.3020352 & ⋯ & 0.7746697 & 0.040002853 & 0.6238410 & 0.6014493 & 0.8367743 & 0.2901885 & 0.02655472 & 0.5637061 & 1 & 0.01647411\\\\\n",
       "\t4 & 1 & 0.3998440 & 0.4512647 & 0.4577333 & 0.5835411 & 0.5835411 & 0.9986997 & 0.7969670 & 0.8089656 & 0.3033495 & ⋯ & 0.7395545 & 0.003252475 & 0.6229287 & 0.5835376 & 0.8346971 & 0.2817212 & 0.02669663 & 0.5646634 & 1 & 0.02398233\\\\\n",
       "\t5 & 1 & 0.4650222 & 0.5384322 & 0.5222978 & 0.5987835 & 0.5987835 & 0.9989731 & 0.7973661 & 0.8093037 & 0.3034750 & ⋯ & 0.7950159 & 0.003877563 & 0.6235207 & 0.5987815 & 0.8399727 & 0.2785138 & 0.02475185 & 0.5756166 & 1 & 0.03549020\\\\\n",
       "\t6 & 1 & 0.3886803 & 0.4151766 & 0.4191338 & 0.5901714 & 0.5902507 & 0.9987581 & 0.7969032 & 0.8087706 & 0.3031158 & ⋯ & 0.7104205 & 0.005277875 & 0.6226046 & 0.5901723 & 0.8299390 & 0.2850871 & 0.02667537 & 0.5645383 & 1 & 0.01953448\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 96\n",
       "\n",
       "| <!--/--> | Bankrupt. &lt;int&gt; | ROA.C..before.interest.and.depreciation.before.interest &lt;dbl&gt; | ROA.A..before.interest.and...after.tax &lt;dbl&gt; | ROA.B..before.interest.and.depreciation.after.tax &lt;dbl&gt; | Operating.Gross.Margin &lt;dbl&gt; | Realized.Sales.Gross.Margin &lt;dbl&gt; | Operating.Profit.Rate &lt;dbl&gt; | Pre.tax.net.Interest.Rate &lt;dbl&gt; | After.tax.net.Interest.Rate &lt;dbl&gt; | Non.industry.income.and.expenditure.revenue &lt;dbl&gt; | ⋯ ⋯ | Net.Income.to.Total.Assets &lt;dbl&gt; | Total.assets.to.GNP.price &lt;dbl&gt; | No.credit.Interval &lt;dbl&gt; | Gross.Profit.to.Sales &lt;dbl&gt; | Net.Income.to.Stockholder.s.Equity &lt;dbl&gt; | Liability.to.Equity &lt;dbl&gt; | Degree.of.Financial.Leverage..DFL. &lt;dbl&gt; | Interest.Coverage.Ratio..Interest.expense.to.EBIT. &lt;dbl&gt; | Net.Income.Flag &lt;int&gt; | Equity.to.Liability &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 0.3705943 | 0.4243894 | 0.4057498 | 0.6014572 | 0.6014572 | 0.9989692 | 0.7968871 | 0.8088094 | 0.3026464 | ⋯ | 0.7168453 | 0.009219440 | 0.6228790 | 0.6014533 | 0.8278902 | 0.2902019 | 0.02660063 | 0.5640501 | 1 | 0.01646874 |\n",
       "| 2 | 1 | 0.4642909 | 0.5382141 | 0.5167300 | 0.6102351 | 0.6102351 | 0.9989460 | 0.7973802 | 0.8093007 | 0.3035564 | ⋯ | 0.7952971 | 0.008323302 | 0.6236517 | 0.6102365 | 0.8399693 | 0.2838460 | 0.26457682 | 0.5701749 | 1 | 0.02079431 |\n",
       "| 3 | 1 | 0.4260713 | 0.4990188 | 0.4722951 | 0.6014500 | 0.6013635 | 0.9988574 | 0.7964034 | 0.8083875 | 0.3020352 | ⋯ | 0.7746697 | 0.040002853 | 0.6238410 | 0.6014493 | 0.8367743 | 0.2901885 | 0.02655472 | 0.5637061 | 1 | 0.01647411 |\n",
       "| 4 | 1 | 0.3998440 | 0.4512647 | 0.4577333 | 0.5835411 | 0.5835411 | 0.9986997 | 0.7969670 | 0.8089656 | 0.3033495 | ⋯ | 0.7395545 | 0.003252475 | 0.6229287 | 0.5835376 | 0.8346971 | 0.2817212 | 0.02669663 | 0.5646634 | 1 | 0.02398233 |\n",
       "| 5 | 1 | 0.4650222 | 0.5384322 | 0.5222978 | 0.5987835 | 0.5987835 | 0.9989731 | 0.7973661 | 0.8093037 | 0.3034750 | ⋯ | 0.7950159 | 0.003877563 | 0.6235207 | 0.5987815 | 0.8399727 | 0.2785138 | 0.02475185 | 0.5756166 | 1 | 0.03549020 |\n",
       "| 6 | 1 | 0.3886803 | 0.4151766 | 0.4191338 | 0.5901714 | 0.5902507 | 0.9987581 | 0.7969032 | 0.8087706 | 0.3031158 | ⋯ | 0.7104205 | 0.005277875 | 0.6226046 | 0.5901723 | 0.8299390 | 0.2850871 | 0.02667537 | 0.5645383 | 1 | 0.01953448 |\n",
       "\n"
      ],
      "text/plain": [
       "  Bankrupt. ROA.C..before.interest.and.depreciation.before.interest\n",
       "1 1         0.3705943                                              \n",
       "2 1         0.4642909                                              \n",
       "3 1         0.4260713                                              \n",
       "4 1         0.3998440                                              \n",
       "5 1         0.4650222                                              \n",
       "6 1         0.3886803                                              \n",
       "  ROA.A..before.interest.and...after.tax\n",
       "1 0.4243894                             \n",
       "2 0.5382141                             \n",
       "3 0.4990188                             \n",
       "4 0.4512647                             \n",
       "5 0.5384322                             \n",
       "6 0.4151766                             \n",
       "  ROA.B..before.interest.and.depreciation.after.tax Operating.Gross.Margin\n",
       "1 0.4057498                                         0.6014572             \n",
       "2 0.5167300                                         0.6102351             \n",
       "3 0.4722951                                         0.6014500             \n",
       "4 0.4577333                                         0.5835411             \n",
       "5 0.5222978                                         0.5987835             \n",
       "6 0.4191338                                         0.5901714             \n",
       "  Realized.Sales.Gross.Margin Operating.Profit.Rate Pre.tax.net.Interest.Rate\n",
       "1 0.6014572                   0.9989692             0.7968871                \n",
       "2 0.6102351                   0.9989460             0.7973802                \n",
       "3 0.6013635                   0.9988574             0.7964034                \n",
       "4 0.5835411                   0.9986997             0.7969670                \n",
       "5 0.5987835                   0.9989731             0.7973661                \n",
       "6 0.5902507                   0.9987581             0.7969032                \n",
       "  After.tax.net.Interest.Rate Non.industry.income.and.expenditure.revenue\n",
       "1 0.8088094                   0.3026464                                  \n",
       "2 0.8093007                   0.3035564                                  \n",
       "3 0.8083875                   0.3020352                                  \n",
       "4 0.8089656                   0.3033495                                  \n",
       "5 0.8093037                   0.3034750                                  \n",
       "6 0.8087706                   0.3031158                                  \n",
       "  <U+22EF>        Net.Income.to.Total.Assets Total.assets.to.GNP.price\n",
       "1 <U+22EF> 0.7168453                  0.009219440              \n",
       "2 <U+22EF> 0.7952971                  0.008323302              \n",
       "3 <U+22EF> 0.7746697                  0.040002853              \n",
       "4 <U+22EF> 0.7395545                  0.003252475              \n",
       "5 <U+22EF> 0.7950159                  0.003877563              \n",
       "6 <U+22EF> 0.7104205                  0.005277875              \n",
       "  No.credit.Interval Gross.Profit.to.Sales Net.Income.to.Stockholder.s.Equity\n",
       "1 0.6228790          0.6014533             0.8278902                         \n",
       "2 0.6236517          0.6102365             0.8399693                         \n",
       "3 0.6238410          0.6014493             0.8367743                         \n",
       "4 0.6229287          0.5835376             0.8346971                         \n",
       "5 0.6235207          0.5987815             0.8399727                         \n",
       "6 0.6226046          0.5901723             0.8299390                         \n",
       "  Liability.to.Equity Degree.of.Financial.Leverage..DFL.\n",
       "1 0.2902019           0.02660063                        \n",
       "2 0.2838460           0.26457682                        \n",
       "3 0.2901885           0.02655472                        \n",
       "4 0.2817212           0.02669663                        \n",
       "5 0.2785138           0.02475185                        \n",
       "6 0.2850871           0.02667537                        \n",
       "  Interest.Coverage.Ratio..Interest.expense.to.EBIT. Net.Income.Flag\n",
       "1 0.5640501                                          1              \n",
       "2 0.5701749                                          1              \n",
       "3 0.5637061                                          1              \n",
       "4 0.5646634                                          1              \n",
       "5 0.5756166                                          1              \n",
       "6 0.5645383                                          1              \n",
       "  Equity.to.Liability\n",
       "1 0.01646874         \n",
       "2 0.02079431         \n",
       "3 0.01647411         \n",
       "4 0.02398233         \n",
       "5 0.03549020         \n",
       "6 0.01953448         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "data <- read.csv(\"data/bankruptcy_prediction/data.csv\", header=T)\n",
    "dim(data)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5eee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>5455</li><li>96</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5455\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5455\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5455   96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1364</li><li>96</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1364\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1364\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1364   96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a sample of data: 6819 obs.\n",
    "set.seed(1)\n",
    "index <- sample(1:nrow(data), round(0.8 * nrow(data), 0))\n",
    "\n",
    "# Create train, test\n",
    "train <- data[index, ]\n",
    "test <- data[-index, ]\n",
    "\n",
    "# Check the new sample data\n",
    "dim(train)\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f53aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ML classification task\n",
    "train_task <- mlr::makeClassifTask(id ='Taiwan_train', data=train, target='Bankrupt.')\n",
    "test_task <- mlr::makeClassifTask(id='Taiwan_test', data=test, target='Bankrupt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1970d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.970674486803519"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.970674486803519"
      ],
      "text/markdown": [
       "**acc:** 0.970674486803519"
      ],
      "text/plain": [
       "      acc \n",
       "0.9706745 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression Lasso (l1)\n",
    "learner <- mlr::makeLearner('classif.LiblineaRL1LogReg')  # Register a machine learning model\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task, proba=T)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b509fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.967741935483871"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.967741935483871"
      ],
      "text/markdown": [
       "**acc:** 0.967741935483871"
      ],
      "text/plain": [
       "      acc \n",
       "0.9677419 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# k-Nearest Neighbor (k=50)\n",
    "learner <- makeLearner('classif.knn', k=50)\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee10f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.958211143695015"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.958211143695015"
      ],
      "text/markdown": [
       "**acc:** 0.958211143695015"
      ],
      "text/plain": [
       "      acc \n",
       "0.9582111 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LDA (drop zero-variance features)\n",
    "learner <- makeLearner('classif.lda')\n",
    "model <- mlr::train(learner, filterFeatures(train_task, method='variance', threshold=0.1))\n",
    "#model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a266b767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.965542521994135"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.965542521994135"
      ],
      "text/markdown": [
       "**acc:** 0.965542521994135"
      ],
      "text/plain": [
       "      acc \n",
       "0.9655425 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "learner <- mlr::makeLearner('classif.rpart')  # Register a machine learning model\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebeae50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.967741935483871"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.967741935483871"
      ],
      "text/markdown": [
       "**acc:** 0.967741935483871"
      ],
      "text/plain": [
       "      acc \n",
       "0.9677419 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "learner <- makeLearner('classif.randomForest')\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9664b34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.972140762463343"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.972140762463343"
      ],
      "text/markdown": [
       "**acc:** 0.972140762463343"
      ],
      "text/plain": [
       "      acc \n",
       "0.9721408 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adabag Boosting\n",
    "learner <- makeLearner('classif.boosting')\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c7b52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>acc:</strong> 0.541788856304985"
      ],
      "text/latex": [
       "\\textbf{acc:} 0.541788856304985"
      ],
      "text/markdown": [
       "**acc:** 0.541788856304985"
      ],
      "text/plain": [
       "      acc \n",
       "0.5417889 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVM\n",
    "learner <- makeLearner('classif.svm', scale=FALSE, kernel='linear')  # linear,polynomial,radial,sigmoid\n",
    "model <- mlr::train(learner, train_task)\n",
    "pred_test <- predict(model, task=test_task)\n",
    "performance(pred_test, measures=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc265e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"4  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'which'</li><li>'rsq'</li><li>'rss'</li><li>'adjr2'</li><li>'cp'</li><li>'bic'</li><li>'outmat'</li><li>'obj'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'which'\n",
       "\\item 'rsq'\n",
       "\\item 'rss'\n",
       "\\item 'adjr2'\n",
       "\\item 'cp'\n",
       "\\item 'bic'\n",
       "\\item 'outmat'\n",
       "\\item 'obj'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'which'\n",
       "2. 'rsq'\n",
       "3. 'rss'\n",
       "4. 'adjr2'\n",
       "5. 'cp'\n",
       "6. 'bic'\n",
       "7. 'outmat'\n",
       "8. 'obj'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"which\"  \"rsq\"    \"rss\"    \"adjr2\"  \"cp\"     \"bic\"    \"outmat\" \"obj\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# applying the backward feature selection to data\n",
    "regfit.bwd=regsubsets(Bankrupt.~.,data=data,method='backward')\n",
    "# summary of backward featur selection\n",
    "reg.summary.bwd=summary(regfit.bwd)\n",
    "# coeficient names for backward feature selection\n",
    "names(reg.summary.bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8cedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 <- cbind(train[, 2:96], class.ind(as.factor(train$label)))\n",
    "\n",
    "# Set labels name\n",
    "names(train2) <- c(names(train)[2:96], \"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"d8\", \"d9\")\n",
    "\n",
    "# Convert data type\n",
    "train2 <- sapply(train2, as.numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d45a482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Bankrupt. ~ ROA.C..before.interest.and.depreciation.before.interest + ROA.A..before.interest.and...after.tax + ROA.B..before.interest.and.depreciation.after.tax + Operating.Gross.Margin + Realized.Sales.Gross.Margin + Operating.Profit.Rate + Pre.tax.net.Interest.Rate + After.tax.net.Interest.Rate + Non.industry.income.and.expenditure.revenue + Continuous.interest.rate..after.tax. + Operating.Expense.Rate + Research.and.development.expense.rate + Cash.flow.rate + Interest.bearing.debt.interest.ra'"
      ],
      "text/latex": [
       "'Bankrupt. \\textasciitilde{} ROA.C..before.interest.and.depreciation.before.interest + ROA.A..before.interest.and...after.tax + ROA.B..before.interest.and.depreciation.after.tax + Operating.Gross.Margin + Realized.Sales.Gross.Margin + Operating.Profit.Rate + Pre.tax.net.Interest.Rate + After.tax.net.Interest.Rate + Non.industry.income.and.expenditure.revenue + Continuous.interest.rate..after.tax. + Operating.Expense.Rate + Research.and.development.expense.rate + Cash.flow.rate + Interest.bearing.debt.interest.ra'"
      ],
      "text/markdown": [
       "'Bankrupt. ~ ROA.C..before.interest.and.depreciation.before.interest + ROA.A..before.interest.and...after.tax + ROA.B..before.interest.and.depreciation.after.tax + Operating.Gross.Margin + Realized.Sales.Gross.Margin + Operating.Profit.Rate + Pre.tax.net.Interest.Rate + After.tax.net.Interest.Rate + Non.industry.income.and.expenditure.revenue + Continuous.interest.rate..after.tax. + Operating.Expense.Rate + Research.and.development.expense.rate + Cash.flow.rate + Interest.bearing.debt.interest.ra'"
      ],
      "text/plain": [
       "[1] \"Bankrupt. ~ ROA.C..before.interest.and.depreciation.before.interest + ROA.A..before.interest.and...after.tax + ROA.B..before.interest.and.depreciation.after.tax + Operating.Gross.Margin + Realized.Sales.Gross.Margin + Operating.Profit.Rate + Pre.tax.net.Interest.Rate + After.tax.net.Interest.Rate + Non.industry.income.and.expenditure.revenue + Continuous.interest.rate..after.tax. + Operating.Expense.Rate + Research.and.development.expense.rate + Cash.flow.rate + Interest.bearing.debt.interest.ra\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the formula to train Neural Network\n",
    "formula <- paste(paste(\"Bankrupt.\", sep=' + '),\n",
    "                 paste(names(train)[2:785], collapse=' + '), sep=' ~ ')\n",
    "substr(formula, start=1, stop=500)  # Print to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710277f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hidden: 1, 30    thresh: 0.01    rep:  1/10    steps: \n",
      "     36\n",
      "\terror: 85.16526\n",
      "\ttime: 0.77 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  2/10    steps: \n",
      "     46\n",
      "\terror: 85.11648\n",
      "\ttime: 0.83 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  3/10    steps: \n",
      "     25\n",
      "\terror: 85.14426\n",
      "\ttime: 0.42 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  4/10    steps: \n",
      "     15\n",
      "\terror: 85.16077\n",
      "\ttime: 0.26 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  5/10    steps: \n",
      "     19\n",
      "\terror: 85.17062\n",
      "\ttime: 0.34 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  6/10    steps: \n",
      "     88\n",
      "\terror: 85.15659\n",
      "\ttime: 1.54 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  7/10    steps: \n",
      "     56\n",
      "\terror: 85.15406\n",
      "\ttime: 1.02 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  8/10    steps: \n",
      "     28\n",
      "\terror: 85.15751\n",
      "\ttime: 0.55 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep:  9/10    steps: \n",
      "     41\n",
      "\terror: 85.16366\n",
      "\ttime: 0.71 secs\n",
      "\n",
      "hidden: 1, 30    thresh: 0.01    rep: 10/10    steps: \n",
      "     22\n",
      "\terror: 85.14731\n",
      "\ttime: 0.38 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the Neural Network model\n",
    "md_nnet <- neuralnet(Bankrupt.~.,\n",
    "                     train,\n",
    "                     hidden=c(1,30),      # Size of the hidden layers\n",
    "                     #threshold=0.1,          # Stopping criteria, a.k.a convergence\n",
    "                     stepmax=5000,            # Maximum training step\n",
    "                     rep=10,                  # Number of training repeat, a.k.a epoch\n",
    "                     lifesign='full',         # Print training process\n",
    "                     lifesign.step=5000,      # Print out every 5000 steps\n",
    "                     algorithm='rprop+',      # Algorithm to calculate the network, 'rprop+'=resilient backpropagation\n",
    "                     learningrate=0.01,       # Learning rate, only use for traditional backpropagation\n",
    "                     err.fct='sse',           # Error function, sse=sum square error, ce=cross-entropy\n",
    "                     act.fct=\"logistic\",      # Activation function, 'logistic' or 'tanh'\n",
    "                     linear.output=F\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49deff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.967736021998167"
      ],
      "text/latex": [
       "0.967736021998167"
      ],
      "text/markdown": [
       "0.967736021998167"
      ],
      "text/plain": [
       "[1] 0.967736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on train\n",
    "y_train_pred <- predict(md_nnet, train[, c(2:96)])\n",
    "mean((max.col(y_train_pred)-1) == train$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "573248a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.967741935483871"
      ],
      "text/latex": [
       "0.967741935483871"
      ],
      "text/markdown": [
       "0.967741935483871"
      ],
      "text/plain": [
       "[1] 0.9677419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on test\n",
    "y_test_pred <- predict(md_nnet, test[, c(2:96)])\n",
    "mean((max.col(y_test_pred)-1) == test$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eff4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hidden: 3, 13    thresh: 0.01    rep:  1/10    steps: \n",
      "    469\n",
      "\terror: 84.96862\n",
      "\ttime: 4.51 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  2/10    steps: \n",
      "     52\n",
      "\terror: 85.08804\n",
      "\ttime: 0.46 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  3/10    steps: \n",
      "     35\n",
      "\terror: 85.16511\n",
      "\ttime: 0.33 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  4/10    steps: \n",
      "    185\n",
      "\terror: 85.09643\n",
      "\ttime: 1.57 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  5/10    steps: \n",
      "    161\n",
      "\terror: 85.09725\n",
      "\ttime: 1.43 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  6/10    steps: \n",
      "     23\n",
      "\terror: 85.14813\n",
      "\ttime: 0.21 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  7/10    steps: \n",
      "     31\n",
      "\terror: 85.16302\n",
      "\ttime: 0.29 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  8/10    steps: \n",
      "     82\n",
      "\terror: 84.90183\n",
      "\ttime: 0.68 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep:  9/10    steps: \n",
      "     74\n",
      "\terror: 85.1314 \n",
      "\ttime: 0.8 secs\n",
      "\n",
      "hidden: 3, 13    thresh: 0.01    rep: 10/10    steps: \n",
      "    109\n",
      "\terror: 85.15248\n",
      "\ttime: 1.01 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the Neural Network model\n",
    "md_nnet <- neuralnet(Bankrupt.~.,\n",
    "                     train,\n",
    "                     hidden=c(3,13),      # Size of the hidden layers\n",
    "                     #threshold=0.1,          # Stopping criteria, a.k.a convergence\n",
    "                     stepmax=5000,            # Maximum training step\n",
    "                     rep=10,                  # Number of training repeat, a.k.a epoch\n",
    "                     lifesign='full',         # Print training process\n",
    "                     lifesign.step=5000,      # Print out every 5000 steps\n",
    "                     algorithm='rprop+',      # Algorithm to calculate the network, 'rprop+'=resilient backpropagation\n",
    "                     learningrate=0.01,       # Learning rate, only use for traditional backpropagation\n",
    "                     err.fct='sse',           # Error function, sse=sum square error, ce=cross-entropy\n",
    "                     act.fct=\"logistic\",      # Activation function, 'logistic' or 'tanh'\n",
    "                     linear.output=F\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d408e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.967736021998167"
      ],
      "text/latex": [
       "0.967736021998167"
      ],
      "text/markdown": [
       "0.967736021998167"
      ],
      "text/plain": [
       "[1] 0.967736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on train\n",
    "y_train_pred <- predict(md_nnet, train[, c(2:96)])\n",
    "mean((max.col(y_train_pred)-1) == train$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8289f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.967741935483871"
      ],
      "text/latex": [
       "0.967741935483871"
      ],
      "text/markdown": [
       "0.967741935483871"
      ],
      "text/plain": [
       "[1] 0.9677419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and evaluation on test\n",
    "y_test_pred <- predict(md_nnet, test[, c(2:96)])\n",
    "mean((max.col(y_test_pred)-1) == test$Bankrupt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df833c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %*% dot product, * element wise product\n",
    "nnet <- function(X, Y, step_size=0.5, reg=0.001, h=10, niteration) {\n",
    "    \"\n",
    "    This function construct a simple 1-hidden layer neural network with ReLU activation function.\n",
    "    \"\n",
    "  \n",
    "    # Get dim of input\n",
    "    N <- nrow(X)  # Number of examples\n",
    "    K <- ncol(Y)  # Number of classes\n",
    "    D <- ncol(X)  # Dimensionality\n",
    "\n",
    "    # Initialize parameters randomly\n",
    "    # Hidden layer\n",
    "    W <- 0.01 * matrix(rnorm(D * h), nrow=D)\n",
    "    b <- matrix(0, nrow=1, ncol=h)\n",
    "    # Output layer\n",
    "    W2 <- 0.01 * matrix(rnorm(h * K), nrow=h)\n",
    "    b2 <- matrix(0, nrow=1, ncol=K)\n",
    "\n",
    "    # Gradient descent loop to update weight and bias\n",
    "    for (i in 0:niteration) {\n",
    "    \n",
    "        #--------------------------------------------\n",
    "        # Forward propagation\n",
    "        #--------------------------------------------\n",
    "        \n",
    "        # Hidden layer, ReLU activation\n",
    "        hidden_layer <- pmax(0, X %*% W + matrix(rep(b, N), nrow=N, byrow=T))  # ReLU\n",
    "        hidden_layer <- matrix(hidden_layer, nrow=N)\n",
    "        \n",
    "        # Class score\n",
    "        scores <- hidden_layer %*% W2 + matrix(rep(b2, N), nrow=N, byrow=T)\n",
    "\n",
    "        # Compute and normalize class probabilities\n",
    "        exp_scores <- exp(scores)\n",
    "        probs <- exp_scores / rowSums(exp_scores)\n",
    "       \n",
    "        # Compute the loss: sofmax and regularization\n",
    "        corect_logprobs <- -log(probs)\n",
    "        data_loss <- sum(corect_logprobs * Y) / N\n",
    "        reg_loss <- 0.5 * reg * sum(W * W) + 0.5 * reg * sum(W2 * W2)\n",
    "        loss <- data_loss + reg_loss\n",
    "        \n",
    "        # Check progress\n",
    "        if (i %% 1000 == 0 | i == niteration) {\n",
    "          print(paste(\"iteration\", i, ': loss', loss))\n",
    "        }\n",
    "        \n",
    "        #--------------------------------------------\n",
    "        # Backward propagation\n",
    "        #--------------------------------------------\n",
    "\n",
    "        # Compute the gradient on scores\n",
    "        dscores <- probs - Y\n",
    "        dscores <- dscores / N\n",
    "\n",
    "        # Backpropate the gradient to the parameters\n",
    "        dW2 <- t(hidden_layer) %*% dscores\n",
    "        db2 <- colSums(dscores)\n",
    "        \n",
    "        # Next backprop into hidden layer\n",
    "        dhidden <- dscores %*% t(W2)\n",
    "        \n",
    "        # Backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] <- 0\n",
    "        \n",
    "        # Finally into W, b\n",
    "        dW <- t(X) %*% dhidden\n",
    "        db <- colSums(dhidden)\n",
    "\n",
    "        # Add regularization gradient contribution\n",
    "        dW2 <- dW2 + reg * W2\n",
    "        dW <- dW + reg * W\n",
    "\n",
    "        # Update parameter \n",
    "        W <- W - step_size * dW\n",
    "        b <- b - step_size * db\n",
    "        W2 <- W2 - step_size * dW2\n",
    "        b2 <- b2 - step_size * db2\n",
    "    }\n",
    "    \n",
    "    return(list(W, b, W2, b2))\n",
    "}\n",
    "\n",
    "# Function to make prediction using Neural Networks\n",
    "nnetPred <- function(X, para=list()) {\n",
    "    \n",
    "    # The trained params of NN\n",
    "    W <- para[[1]]\n",
    "    b <- para[[2]]\n",
    "    W2 <- para[[3]]\n",
    "    b2 <- para[[4]]\n",
    "\n",
    "    N <- nrow(X)\n",
    "    hidden_layer <- pmax(0, X %*% W + matrix(rep(b, N), nrow=N, byrow=T)) \n",
    "    hidden_layer <- matrix(hidden_layer, nrow=N)\n",
    "    scores <- hidden_layer %*% W2 + matrix(rep(b2, N), nrow=N, byrow=T)  # Linear output\n",
    "    predicted_class <- apply(scores, 1, which.max)\n",
    "\n",
    "    return(predicted_class)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b570c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing train, test data\n",
    "nzv <- nearZeroVar(train)  # Drop zero-variance variables\n",
    "nzv.nolabel <- nzv - 1\n",
    "\n",
    "# Train data\n",
    "X_train <- as.matrix(train[, -1])  # Data matrix (each row = single example)\n",
    "N <- nrow(X_train)  # Number of examples\n",
    "y_train <- train[, 1]  # Class labels\n",
    "\n",
    "K <- length(unique(y_train))  # Number of classes\n",
    "X_train_proccessed <- X_train[, -nzv.nolabel] / max(X_train)  # Scale train data\n",
    "D <- ncol(X_train_proccessed)  # Dimensionality\n",
    "\n",
    "# Test data\n",
    "X_test <- as.matrix(test[, -1])  # Data matrix (each row = single example)\n",
    "y_test <- test[, 1]  # Class labels\n",
    "X_test_proccessed <- X_test[, -nzv.nolabel] / max(X_train)  # Scale test data using train info\n",
    "\n",
    "# Dummitize the y_train\n",
    "y_train_dummy <- matrix(0, N, K)\n",
    "for (i in 1:N) {\n",
    "    y_train_dummy[i, y_train[i] + 1] <- 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cc6aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"iteration 0 : loss 0.693045872306736\"\n",
      "[1] \"iteration 1000 : loss 0.140033016335533\"\n",
      "[1] \"iteration 2000 : loss 0.139099533482792\"\n",
      "[1] \"iteration 3000 : loss 0.138954342781147\"\n",
      "[1] \"iteration 4000 : loss 0.138866673116809\"\n",
      "[1] \"iteration 5000 : loss 0.138795059977756\"\n",
      "[1] \"iteration 6000 : loss 0.138758968275854\"\n",
      "[1] \"iteration 7000 : loss 0.138737711912217\"\n"
     ]
    }
   ],
   "source": [
    "#Run the Neural Networks function\n",
    "nnet.mnist <- nnet(X_train_proccessed, y_train_dummy, niteration=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a749e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Train accuracy: 0.967736021998167\"\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on train set\n",
    "predicted_class <- nnetPred(X_train_proccessed, nnet.mnist)\n",
    "print(paste('Train accuracy:', mean(predicted_class == (y_train+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8baf25aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Test accuracy: 0.967741935483871\"\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test set\n",
    "predicted_class <- nnetPred(X_test_proccessed, nnet.mnist)\n",
    "print(paste('Test accuracy:', mean(predicted_class == (y_test+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77359075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e9f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef7e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
